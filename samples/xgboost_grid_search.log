
self.params:  {'objective': 'binary:logistic', 'learning_rate': [0.025, 0.25], 'silent': 1, 'nthread': -1, 'max_depth': [4, 6]}
options : {'learning_rate': 0.025, 'max_depth': 4}
params:  {'objective': 'binary:logistic', 'max_depth': 4, 'learning_rate': 0.025, 'silent': 1, 'nthread': -1}
------------- cv fold for params:  {'objective': 'binary:logistic', 'max_depth': 4, 'learning_rate': 0.025, 'silent': 1, 'nthread': -1}
    evals_result:  {'validation_0': {'logloss': ['0.67782', '0.66311', '0.64914', '0.63585', '0.62318', '0.61106', '0.59936', '0.58828', '0.57752', '0.56724', '0.55686', '0.54739', '0.53875', '0.52904', '0.52107', '0.51205', '0.50468', '0.49630', '0.48946', '0.48243', '0.47609', '0.46877', '0.46288', '0.45678', '0.45126', '0.44481', '0.43934', '0.43363', '0.42849', '0.42312', '0.41868', '0.41399', '0.40908', '0.40513', '0.40019', '0.39634', '0.39168', '0.38807', '0.38381', '0.38052', '0.37724', '0.37358', '0.37030', '0.36669', '0.36353', '0.36011', '0.35726', '0.35410', '0.35145', '0.34829', '0.34586', '0.34294', '0.34041', '0.33785', '0.33564', '0.33283', '0.33028', '0.32780', '0.32549', '0.32319', '0.32094', '0.31880', '0.31668', '0.31470', '0.31276', '0.31081', '0.30900', '0.30718', '0.30538', '0.30368', '0.30198', '0.30040', '0.29884', '0.29700', '0.29553', '0.29403', '0.29262', '0.29127', '0.28989', '0.28858', '0.28734', '0.28569', '0.28450', '0.28329', '0.28209', '0.28097', '0.27990', '0.27880', '0.27724', '0.27618', '0.27517', '0.27416', '0.27318', '0.27239', '0.27150', '0.27058', '0.26972', '0.26844', '0.26763', '0.26679']}}
    evals_result:  {'validation_0': {'logloss': ['0.67778', '0.66312', '0.64858', '0.63530', '0.62260', '0.61045', '0.59834', '0.58727', '0.57666', '0.56713', '0.55689', '0.54815', '0.53819', '0.53011', '0.52087', '0.51342', '0.50492', '0.49666', '0.48950', '0.48191', '0.47524', '0.46856', '0.46247', '0.45575', '0.45042', '0.44528', '0.43928', '0.43404', '0.42876', '0.42386', '0.41858', '0.41441', '0.41020', '0.40529', '0.40062', '0.39699', '0.39292', '0.38934', '0.38551', '0.38231', '0.37822', '0.37521', '0.37178', '0.36894', '0.36526', '0.36258', '0.35951', '0.35687', '0.35398', '0.35073', '0.34851', '0.34544', '0.34285', '0.34068', '0.33837', '0.33603', '0.33368', '0.33167', '0.32910', '0.32720', '0.32547', '0.32367', '0.32194', '0.32026', '0.31843', '0.31619', '0.31463', '0.31296', '0.31115', '0.30954', '0.30789', '0.30654', '0.30491', '0.30346', '0.30197', '0.30018', '0.29882', '0.29767', '0.29628', '0.29503', '0.29398', '0.29236', '0.29113', '0.29000', '0.28879', '0.28773', '0.28684', '0.28539', '0.28439', '0.28357', '0.28255', '0.28126', '0.28024', '0.27936', '0.27864', '0.27778', '0.27686', '0.27606', '0.27526', '0.27464']}}
    evals_result:  {'validation_0': {'logloss': ['0.67783', '0.66328', '0.64933', '0.63603', '0.62339', '0.61128', '0.59968', '0.58859', '0.57857', '0.56843', '0.55918', '0.54862', '0.54015', '0.53037', '0.52148', '0.51393', '0.50517', '0.49726', '0.49003', '0.48267', '0.47600', '0.46913', '0.46293', '0.45734', '0.45070', '0.44472', '0.43933', '0.43373', '0.42868', '0.42304', '0.41799', '0.41341', '0.40868', '0.40373', '0.39997', '0.39521', '0.39165', '0.38758', '0.38322', '0.37998', '0.37626', '0.37280', '0.36927', '0.36603', '0.36269', '0.35927', '0.35662', '0.35319', '0.35070', '0.34781', '0.34483', '0.34248', '0.33953', '0.33721', '0.33467', '0.33208', '0.33009', '0.32774', '0.32555', '0.32347', '0.32124', '0.31933', '0.31726', '0.31531', '0.31343', '0.31164', '0.30976', '0.30801', '0.30631', '0.30461', '0.30299', '0.30133', '0.29984', '0.29834', '0.29687', '0.29538', '0.29364', '0.29230', '0.29091', '0.28972', '0.28845', '0.28720', '0.28594', '0.28478', '0.28355', '0.28235', '0.28118', '0.28004', '0.27875', '0.27771', '0.27671', '0.27568', '0.27472', '0.27366', '0.27270', '0.27174', '0.27053', '0.26967', '0.26879', '0.26799']}}
    evals_result:  {'validation_0': {'logloss': ['0.67780', '0.66318', '0.64914', '0.63579', '0.62305', '0.61090', '0.59869', '0.58763', '0.57704', '0.56682', '0.55762', '0.54775', '0.53924', '0.53065', '0.52286', '0.51442', '0.50717', '0.49984', '0.49310', '0.48633', '0.47858', '0.47155', '0.46530', '0.45977', '0.45300', '0.44737', '0.44143', '0.43612', '0.43055', '0.42573', '0.42015', '0.41513', '0.40997', '0.40596', '0.40183', '0.39699', '0.39270', '0.38856', '0.38477', '0.38146', '0.37729', '0.37359', '0.37060', '0.36676', '0.36382', '0.36053', '0.35701', '0.35458', '0.35155', '0.34922', '0.34603', '0.34369', '0.34092', '0.33843', '0.33602', '0.33396', '0.33161', '0.32894', '0.32664', '0.32451', '0.32232', '0.32020', '0.31824', '0.31630', '0.31434', '0.31237', '0.31061', '0.30875', '0.30700', '0.30507', '0.30349', '0.30182', '0.30035', '0.29882', '0.29728', '0.29579', '0.29433', '0.29297', '0.29171', '0.29041', '0.28881', '0.28756', '0.28630', '0.28512', '0.28394', '0.28277', '0.28167', '0.28061', '0.27919', '0.27825', '0.27725', '0.27623', '0.27528', '0.27426', '0.27303', '0.27214', '0.27127', '0.27039', '0.26959', '0.26878']}}
    evals_result:  {'validation_0': {'logloss': ['0.67718', '0.66201', '0.64758', '0.63444', '0.62131', '0.60933', '0.59786', '0.58695', '0.57599', '0.56596', '0.55688', '0.54766', '0.53934', '0.53085', '0.52320', '0.51426', '0.50719', '0.49933', '0.49134', '0.48461', '0.47799', '0.47204', '0.46503', '0.45910', '0.45393', '0.44762', '0.44226', '0.43673', '0.43188', '0.42672', '0.42204', '0.41792', '0.41322', '0.40902', '0.40544', '0.40089', '0.39675', '0.39309', '0.38982', '0.38580', '0.38286', '0.37875', '0.37595', '0.37269', '0.36949', '0.36629', '0.36386', '0.36038', '0.35811', '0.35523', '0.35256', '0.34995', '0.34780', '0.34485', '0.34297', '0.34064', '0.33793', '0.33608', '0.33394', '0.33187', '0.32991', '0.32797', '0.32587', '0.32388', '0.32185', '0.31992', '0.31862', '0.31682', '0.31482', '0.31308', '0.31142', '0.30994', '0.30832', '0.30678', '0.30515', '0.30369', '0.30227', '0.30089', '0.29956', '0.29826', '0.29679', '0.29552', '0.29431', '0.29315', '0.29201', '0.29089', '0.28981', '0.28873', '0.28771', '0.28647', '0.28550', '0.28455', '0.28363', '0.28273', '0.28168', '0.28079', '0.27996', '0.27914', '0.27824', '0.27745']}}
Final average loss is  0.38622772
loss:  0.38622772  for options:  {'learning_rate': 0.025, 'max_depth': 4}
>>>> Better options is found


options : {'learning_rate': 0.025, 'max_depth': 6}
params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.025, 'max_depth': 6, 'nthread': -1}
------------- cv fold for params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.025, 'max_depth': 6, 'nthread': -1}
    evals_result:  {'validation_0': {'logloss': ['0.67687', '0.66135', '0.64662', '0.63250', '0.61912', '0.60524', '0.59203', '0.57931', '0.56728', '0.55561', '0.54447', '0.53369', '0.52332', '0.51351', '0.50406', '0.49498', '0.48618', '0.47762', '0.46951', '0.46160', '0.45397', '0.44680', '0.43992', '0.43331', '0.42681', '0.42062', '0.41466', '0.40878', '0.40322', '0.39773', '0.39254', '0.38753', '0.38271', '0.37790', '0.37337', '0.36897', '0.36474', '0.36057', '0.35644', '0.35260', '0.34875', '0.34510', '0.34152', '0.33800', '0.33472', '0.33140', '0.32821', '0.32525', '0.32227', '0.31950', '0.31670', '0.31397', '0.31159', '0.30914', '0.30664', '0.30424', '0.30200', '0.29951', '0.29735', '0.29500', '0.29299', '0.29079', '0.28882', '0.28705', '0.28507', '0.28329', '0.28133', '0.27978', '0.27805', '0.27637', '0.27484', '0.27332', '0.27167', '0.27017', '0.26874', '0.26717', '0.26583', '0.26445', '0.26307', '0.26180', '0.26042', '0.25921', '0.25804', '0.25687', '0.25552', '0.25450', '0.25341', '0.25249', '0.25153', '0.25051', '0.24960', '0.24854', '0.24762', '0.24673', '0.24589', '0.24515', '0.24420', '0.24346', '0.24276', '0.24195']}}
    evals_result:  {'validation_0': {'logloss': ['0.67702', '0.66167', '0.64707', '0.63308', '0.61978', '0.60703', '0.59485', '0.58220', '0.56995', '0.55835', '0.54795', '0.53727', '0.52698', '0.51714', '0.50762', '0.49861', '0.48962', '0.48117', '0.47323', '0.46559', '0.45832', '0.45100', '0.44423', '0.43774', '0.43142', '0.42527', '0.41919', '0.41363', '0.40800', '0.40273', '0.39732', '0.39246', '0.38736', '0.38278', '0.37833', '0.37373', '0.36946', '0.36545', '0.36129', '0.35751', '0.35366', '0.35015', '0.34670', '0.34318', '0.34002', '0.33674', '0.33371', '0.33058', '0.32772', '0.32472', '0.32205', '0.31952', '0.31680', '0.31417', '0.31173', '0.30931', '0.30698', '0.30489', '0.30261', '0.30043', '0.29847', '0.29642', '0.29441', '0.29262', '0.29088', '0.28899', '0.28720', '0.28560', '0.28393', '0.28231', '0.28062', '0.27917', '0.27767', '0.27623', '0.27493', '0.27351', '0.27228', '0.27092', '0.26958', '0.26829', '0.26710', '0.26585', '0.26479', '0.26369', '0.26256', '0.26146', '0.26048', '0.25937', '0.25835', '0.25736', '0.25645', '0.25558', '0.25465', '0.25381', '0.25292', '0.25203', '0.25121', '0.25047', '0.24978', '0.24902']}}
    evals_result:  {'validation_0': {'logloss': ['0.67589', '0.65947', '0.64381', '0.62886', '0.61455', '0.60090', '0.58777', '0.57530', '0.56317', '0.55163', '0.54058', '0.52992', '0.51970', '0.50995', '0.50043', '0.49140', '0.48289', '0.47445', '0.46658', '0.45885', '0.45151', '0.44446', '0.43770', '0.43107', '0.42466', '0.41861', '0.41261', '0.40681', '0.40134', '0.39609', '0.39085', '0.38574', '0.38093', '0.37630', '0.37173', '0.36732', '0.36312', '0.35904', '0.35497', '0.35110', '0.34735', '0.34373', '0.34022', '0.33686', '0.33376', '0.33052', '0.32743', '0.32447', '0.32156', '0.31894', '0.31617', '0.31349', '0.31096', '0.30848', '0.30601', '0.30383', '0.30151', '0.29912', '0.29697', '0.29501', '0.29329', '0.29115', '0.28955', '0.28772', '0.28579', '0.28401', '0.28266', '0.28090', '0.27957', '0.27794', '0.27632', '0.27494', '0.27369', '0.27226', '0.27082', '0.26947', '0.26816', '0.26693', '0.26574', '0.26460', '0.26331', '0.26206', '0.26079', '0.25964', '0.25845', '0.25730', '0.25623', '0.25513', '0.25414', '0.25312', '0.25212', '0.25122', '0.25025', '0.24940', '0.24865', '0.24778', '0.24687', '0.24619', '0.24541', '0.24465']}}
    evals_result:  {'validation_0': {'logloss': ['0.67592', '0.65953', '0.64386', '0.62897', '0.61480', '0.60150', '0.58857', '0.57610', '0.56439', '0.55356', '0.54251', '0.53257', '0.52236', '0.51256', '0.50298', '0.49446', '0.48564', '0.47727', '0.46968', '0.46181', '0.45431', '0.44692', '0.43992', '0.43322', '0.42695', '0.42073', '0.41462', '0.40873', '0.40304', '0.39736', '0.39205', '0.38694', '0.38197', '0.37718', '0.37251', '0.36810', '0.36375', '0.35961', '0.35554', '0.35152', '0.34775', '0.34398', '0.34043', '0.33698', '0.33363', '0.33041', '0.32719', '0.32420', '0.32115', '0.31828', '0.31549', '0.31259', '0.30998', '0.30733', '0.30493', '0.30249', '0.30001', '0.29770', '0.29547', '0.29337', '0.29120', '0.28920', '0.28717', '0.28530', '0.28334', '0.28157', '0.27980', '0.27829', '0.27667', '0.27499', '0.27349', '0.27202', '0.27034', '0.26902', '0.26769', '0.26631', '0.26484', '0.26362', '0.26213', '0.26086', '0.25964', '0.25845', '0.25718', '0.25606', '0.25498', '0.25379', '0.25273', '0.25173', '0.25076', '0.24987', '0.24892', '0.24802', '0.24717', '0.24636', '0.24552', '0.24454', '0.24371', '0.24282', '0.24211', '0.24132']}}
    evals_result:  {'validation_0': {'logloss': ['0.67679', '0.66126', '0.64646', '0.63239', '0.61900', '0.60617', '0.59399', '0.58222', '0.57110', '0.56044', '0.55003', '0.54029', '0.53067', '0.52180', '0.51309', '0.50474', '0.49668', '0.48764', '0.47929', '0.47103', '0.46329', '0.45552', '0.44837', '0.44147', '0.43484', '0.42842', '0.42225', '0.41631', '0.41057', '0.40504', '0.39966', '0.39455', '0.38958', '0.38471', '0.38013', '0.37568', '0.37128', '0.36702', '0.36303', '0.35903', '0.35524', '0.35145', '0.34798', '0.34441', '0.34105', '0.33780', '0.33458', '0.33153', '0.32855', '0.32566', '0.32269', '0.31993', '0.31732', '0.31482', '0.31226', '0.30991', '0.30757', '0.30518', '0.30308', '0.30098', '0.29896', '0.29685', '0.29490', '0.29292', '0.29113', '0.28921', '0.28732', '0.28570', '0.28410', '0.28253', '0.28100', '0.27956', '0.27813', '0.27669', '0.27538', '0.27391', '0.27260', '0.27135', '0.27009', '0.26885', '0.26763', '0.26648', '0.26524', '0.26403', '0.26288', '0.26191', '0.26084', '0.25987', '0.25898', '0.25798', '0.25703', '0.25622', '0.25532', '0.25456', '0.25383', '0.25298', '0.25217', '0.25140', '0.25072', '0.25003']}}
Final average loss is  0.36233724
loss:  0.36233724  for options:  {'learning_rate': 0.025, 'max_depth': 6}
>>>> Better options is found


options : {'learning_rate': 0.25, 'max_depth': 4}
params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.25, 'max_depth': 4, 'nthread': -1}
------------- cv fold for params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.25, 'max_depth': 4, 'nthread': -1}
    evals_result:  {'validation_0': {'logloss': ['0.55628', '0.47559', '0.41076', '0.37146', '0.33678', '0.31279', '0.29517', '0.28211', '0.26735', '0.25914', '0.25266', '0.24580', '0.24104', '0.23647', '0.23429', '0.23123', '0.22877', '0.22764', '0.22591', '0.22375', '0.22246', '0.22057', '0.21885', '0.21804', '0.21465', '0.21366', '0.21328', '0.21299', '0.21149', '0.21038', '0.21030', '0.21160', '0.21143', '0.21069', '0.21095', '0.20942', '0.20908', '0.20878', '0.20879', '0.20909', '0.20844', '0.20847', '0.20808', '0.20771', '0.20750', '0.20790', '0.20739', '0.20748', '0.20660', '0.20767', '0.20748', '0.20684', '0.20569', '0.20587', '0.20607', '0.20547', '0.20555', '0.20558', '0.20567', '0.20716', '0.20777', '0.20760', '0.20798', '0.20900', '0.20855', '0.20861', '0.20779', '0.20865', '0.20926', '0.20933', '0.20945', '0.20974', '0.20981', '0.21025', '0.21014', '0.20990', '0.20898', '0.20955', '0.20911', '0.20964', '0.20968', '0.20940', '0.20942', '0.20933', '0.20959', '0.20998', '0.21064', '0.21050', '0.21052', '0.21032', '0.20901', '0.20947', '0.20904', '0.20925', '0.20850', '0.20881', '0.20905', '0.20918', '0.20894', '0.20907']}}
    evals_result:  {'validation_0': {'logloss': ['0.55598', '0.47710', '0.40977', '0.36982', '0.34268', '0.31884', '0.30428', '0.28731', '0.27691', '0.26847', '0.26373', '0.25544', '0.25142', '0.24774', '0.24311', '0.24050', '0.23828', '0.23252', '0.23044', '0.22877', '0.22615', '0.22491', '0.22417', '0.22264', '0.22010', '0.22016', '0.21887', '0.21825', '0.21748', '0.21711', '0.21601', '0.21331', '0.21252', '0.21186', '0.21180', '0.21025', '0.21002', '0.20947', '0.21075', '0.21017', '0.21069', '0.20968', '0.20959', '0.20913', '0.20895', '0.20877', '0.20947', '0.20875', '0.20886', '0.20932', '0.20955', '0.20973', '0.21050', '0.20951', '0.20911', '0.20953', '0.21015', '0.20980', '0.20967', '0.20929', '0.20854', '0.20933', '0.20941', '0.20917', '0.20859', '0.20853', '0.20902', '0.20923', '0.20889', '0.20901', '0.20777', '0.20762', '0.20749', '0.20732', '0.20696', '0.20689', '0.20705', '0.20723', '0.20742', '0.20742', '0.20808', '0.20842', '0.20801', '0.20853', '0.20864', '0.20824', '0.20819', '0.20904', '0.20847', '0.20891', '0.20900', '0.20935', '0.20946', '0.20933', '0.20982', '0.20976', '0.21051', '0.21026', '0.21095', '0.21125']}}
    evals_result:  {'validation_0': {'logloss': ['0.55694', '0.47817', '0.41073', '0.36909', '0.34041', '0.31337', '0.29540', '0.28242', '0.27213', '0.26381', '0.25693', '0.24706', '0.24416', '0.24010', '0.23697', '0.23321', '0.23097', '0.22870', '0.22658', '0.22585', '0.22385', '0.22171', '0.21912', '0.21737', '0.21514', '0.21445', '0.21308', '0.21313', '0.21249', '0.21120', '0.21041', '0.20878', '0.20791', '0.20710', '0.20730', '0.20710', '0.20679', '0.20655', '0.20699', '0.20617', '0.20704', '0.20759', '0.20858', '0.20756', '0.20738', '0.20724', '0.20681', '0.20719', '0.20651', '0.20594', '0.20562', '0.20591', '0.20643', '0.20622', '0.20683', '0.20662', '0.20605', '0.20675', '0.20590', '0.20598', '0.20644', '0.20652', '0.20642', '0.20542', '0.20535', '0.20468', '0.20544', '0.20512', '0.20489', '0.20508', '0.20528', '0.20556', '0.20566', '0.20541', '0.20559', '0.20584', '0.20587', '0.20573', '0.20615', '0.20625', '0.20585', '0.20565', '0.20506', '0.20527', '0.20525', '0.20606', '0.20607', '0.20606', '0.20645', '0.20640', '0.20625', '0.20616', '0.20622', '0.20639', '0.20662', '0.20703', '0.20636', '0.20681', '0.20716', '0.20694']}}
    evals_result:  {'validation_0': {'logloss': ['0.55622', '0.47284', '0.41729', '0.37077', '0.34319', '0.31607', '0.29833', '0.28611', '0.27266', '0.26375', '0.25709', '0.25125', '0.24722', '0.24104', '0.23712', '0.23289', '0.23071', '0.22805', '0.22415', '0.22205', '0.22112', '0.21899', '0.21805', '0.21630', '0.21560', '0.21492', '0.21349', '0.21082', '0.21024', '0.20965', '0.21009', '0.21042', '0.20938', '0.20880', '0.20854', '0.20803', '0.20782', '0.20588', '0.20563', '0.20557', '0.20571', '0.20474', '0.20474', '0.20504', '0.20298', '0.20223', '0.20262', '0.20199', '0.20225', '0.20268', '0.20242', '0.20245', '0.20255', '0.20255', '0.20196', '0.20190', '0.20188', '0.20175', '0.20210', '0.20211', '0.20135', '0.20131', '0.20197', '0.20181', '0.20189', '0.20161', '0.20183', '0.20124', '0.20164', '0.20159', '0.20250', '0.20296', '0.20301', '0.20269', '0.20291', '0.20264', '0.20107', '0.20151', '0.20143', '0.20188', '0.20184', '0.20083', '0.20086', '0.20116', '0.20146', '0.20207', '0.20192', '0.20192', '0.20263', '0.20280', '0.20259', '0.20256', '0.20194', '0.20176', '0.20151', '0.20142', '0.20082', '0.20064', '0.20053', '0.20059']}}
    evals_result:  {'validation_0': {'logloss': ['0.55198', '0.46645', '0.41111', '0.37451', '0.34335', '0.32379', '0.30636', '0.29371', '0.28402', '0.27218', '0.26620', '0.26146', '0.25757', '0.25050', '0.24670', '0.24247', '0.24118', '0.23869', '0.23699', '0.23528', '0.23315', '0.23216', '0.23074', '0.22889', '0.22925', '0.22787', '0.22633', '0.22562', '0.22515', '0.22519', '0.22592', '0.22562', '0.22489', '0.22413', '0.22435', '0.22442', '0.22413', '0.22358', '0.22394', '0.22397', '0.22325', '0.22293', '0.22247', '0.22247', '0.22205', '0.22213', '0.22217', '0.22120', '0.22121', '0.22077', '0.22131', '0.22149', '0.22186', '0.22185', '0.22172', '0.22192', '0.22206', '0.22309', '0.22250', '0.22146', '0.22095', '0.22095', '0.22081', '0.22036', '0.22044', '0.22032', '0.22082', '0.22092', '0.22067', '0.22057', '0.22136', '0.22165', '0.22228', '0.22311', '0.22335', '0.22347', '0.22369', '0.22410', '0.22399', '0.22282', '0.22280', '0.22254', '0.22265', '0.22315', '0.22286', '0.22264', '0.22292', '0.22327', '0.22325', '0.22322', '0.22345', '0.22348', '0.22404', '0.22440', '0.22429', '0.22395', '0.22404', '0.22462', '0.22463', '0.22504']}}
Final average loss is  0.2289096
loss:  0.2289096  for options:  {'learning_rate': 0.25, 'max_depth': 4}
>>>> Better options is found


options : {'learning_rate': 0.25, 'max_depth': 6}
params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.25, 'max_depth': 6, 'nthread': -1}
------------- cv fold for params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.25, 'max_depth': 6, 'nthread': -1}
    evals_result:  {'validation_0': {'logloss': ['0.54803', '0.45003', '0.38440', '0.34126', '0.31054', '0.28864', '0.26964', '0.25540', '0.24535', '0.23849', '0.23295', '0.22806', '0.22359', '0.21970', '0.21722', '0.21588', '0.21427', '0.21212', '0.21061', '0.20954', '0.20767', '0.20664', '0.20567', '0.20491', '0.20516', '0.20492', '0.20446', '0.20402', '0.20488', '0.20404', '0.20375', '0.20369', '0.20351', '0.20609', '0.20527', '0.20500', '0.20515', '0.20466', '0.20446', '0.20460', '0.20488', '0.20526', '0.20432', '0.20456', '0.20433', '0.20539', '0.20561', '0.20485', '0.20579', '0.20532', '0.20678', '0.20641', '0.20668', '0.20689', '0.20765', '0.20769', '0.20837', '0.20949', '0.21068', '0.21149', '0.21149', '0.21155', '0.21194', '0.21225', '0.21356', '0.21389', '0.21497', '0.21472', '0.21494', '0.21502', '0.21468', '0.21505', '0.21518', '0.21586', '0.21572', '0.21610', '0.21622', '0.21650', '0.21778', '0.21800', '0.21759', '0.21717', '0.21697', '0.21669', '0.21672', '0.21745', '0.21719', '0.21823', '0.21895', '0.21919', '0.21945', '0.21944', '0.22012', '0.22014', '0.22066', '0.22119', '0.22210', '0.22258', '0.22225', '0.22162']}}
    evals_result:  {'validation_0': {'logloss': ['0.54930', '0.46044', '0.39630', '0.34843', '0.31798', '0.29349', '0.27569', '0.26278', '0.25314', '0.24483', '0.23922', '0.23448', '0.23061', '0.22743', '0.22537', '0.22284', '0.22126', '0.21985', '0.21923', '0.21793', '0.21676', '0.21416', '0.21175', '0.21276', '0.21276', '0.21265', '0.21137', '0.21068', '0.21135', '0.21139', '0.21176', '0.21224', '0.21214', '0.21214', '0.21102', '0.21160', '0.21359', '0.21337', '0.21350', '0.21357', '0.21366', '0.21425', '0.21417', '0.21489', '0.21481', '0.21461', '0.21533', '0.21514', '0.21582', '0.21483', '0.21490', '0.21438', '0.21527', '0.21494', '0.21520', '0.21482', '0.21535', '0.21729', '0.21785', '0.21859', '0.21792', '0.21829', '0.21811', '0.21809', '0.21757', '0.21770', '0.21950', '0.21813', '0.21847', '0.21943', '0.21847', '0.21953', '0.21953', '0.21911', '0.21947', '0.21893', '0.22017', '0.22013', '0.21976', '0.22069', '0.22074', '0.22081', '0.22068', '0.22112', '0.22107', '0.22116', '0.22120', '0.22094', '0.22119', '0.22169', '0.22292', '0.22268', '0.22241', '0.22160', '0.22236', '0.22236', '0.22288', '0.22309', '0.22316', '0.22327']}}
    evals_result:  {'validation_0': {'logloss': ['0.53944', '0.44434', '0.38388', '0.34113', '0.31010', '0.28832', '0.27265', '0.26255', '0.25163', '0.24355', '0.23761', '0.23289', '0.22859', '0.22621', '0.22379', '0.22141', '0.22069', '0.21837', '0.21555', '0.21409', '0.21183', '0.21141', '0.21141', '0.20863', '0.20772', '0.20773', '0.20773', '0.20803', '0.20759', '0.20654', '0.20634', '0.20637', '0.20630', '0.20536', '0.20504', '0.20445', '0.20338', '0.20256', '0.20251', '0.20305', '0.20240', '0.20454', '0.20440', '0.20370', '0.20291', '0.20358', '0.20287', '0.20303', '0.20318', '0.20359', '0.20340', '0.20434', '0.20426', '0.20486', '0.20578', '0.20572', '0.20502', '0.20678', '0.20790', '0.20836', '0.20766', '0.20746', '0.20586', '0.20647', '0.20601', '0.20625', '0.20635', '0.20679', '0.20595', '0.20692', '0.20635', '0.20659', '0.20681', '0.20651', '0.20657', '0.20723', '0.20736', '0.20881', '0.20931', '0.21057', '0.20978', '0.20970', '0.21022', '0.21104', '0.21173', '0.21189', '0.21242', '0.21396', '0.21416', '0.21516', '0.21559', '0.21626', '0.21623', '0.21675', '0.21695', '0.21789', '0.21800', '0.21841', '0.21932', '0.21936']}}
    evals_result:  {'validation_0': {'logloss': ['0.53969', '0.44798', '0.38878', '0.34309', '0.31053', '0.28514', '0.26877', '0.25490', '0.24482', '0.23664', '0.23043', '0.22621', '0.22253', '0.21925', '0.21496', '0.21160', '0.20910', '0.20872', '0.20584', '0.20478', '0.20345', '0.20311', '0.20268', '0.20160', '0.20148', '0.20046', '0.19895', '0.19774', '0.19717', '0.19621', '0.19638', '0.19665', '0.19629', '0.19745', '0.19787', '0.19773', '0.19658', '0.19601', '0.19618', '0.19597', '0.19632', '0.19596', '0.19622', '0.19632', '0.19717', '0.19744', '0.19746', '0.19794', '0.19784', '0.19812', '0.19769', '0.19798', '0.19838', '0.19767', '0.19842', '0.19832', '0.19835', '0.19896', '0.19941', '0.19958', '0.19950', '0.20011', '0.20035', '0.20061', '0.20124', '0.20159', '0.20218', '0.20175', '0.20207', '0.20179', '0.20256', '0.20278', '0.20292', '0.20347', '0.20334', '0.20368', '0.20349', '0.20330', '0.20362', '0.20398', '0.20454', '0.20428', '0.20469', '0.20537', '0.20574', '0.20561', '0.20581', '0.20581', '0.20687', '0.20756', '0.20752', '0.20827', '0.20917', '0.21003', '0.21089', '0.21119', '0.21199', '0.21240', '0.21251', '0.21230']}}
    evals_result:  {'validation_0': {'logloss': ['0.54800', '0.46129', '0.39514', '0.35028', '0.31824', '0.29373', '0.27722', '0.26414', '0.25401', '0.24719', '0.24176', '0.23820', '0.23393', '0.23107', '0.22838', '0.22666', '0.22536', '0.22383', '0.22175', '0.22079', '0.22021', '0.21938', '0.22001', '0.21982', '0.22032', '0.21874', '0.21763', '0.21789', '0.21758', '0.21747', '0.21741', '0.21849', '0.21841', '0.21876', '0.21973', '0.21948', '0.21948', '0.21976', '0.22035', '0.22014', '0.22017', '0.21975', '0.21993', '0.21991', '0.22065', '0.22011', '0.22067', '0.22158', '0.22272', '0.22351', '0.22362', '0.22402', '0.22407', '0.22514', '0.22414', '0.22526', '0.22553', '0.22560', '0.22590', '0.22637', '0.22617', '0.22723', '0.22820', '0.22861', '0.22867', '0.22894', '0.22862', '0.22879', '0.22985', '0.23082', '0.23122', '0.23137', '0.23194', '0.23236', '0.23227', '0.23271', '0.23279', '0.23362', '0.23348', '0.23433', '0.23442', '0.23499', '0.23483', '0.23536', '0.23550', '0.23653', '0.23703', '0.23765', '0.23880', '0.23933', '0.23945', '0.23979', '0.23972', '0.24026', '0.24071', '0.24187', '0.24249', '0.24473', '0.24637', '0.24637']}}
Final average loss is  0.22648896
loss:  0.22648896  for options:  {'learning_rate': 0.25, 'max_depth': 6}


>>>> Better options is found
-------------- Final Result ----------------
best score:  0.22648896
best params:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.25, 'max_depth': 6, 'nthread': -1}
------------- precict with pararms:  {'silent': 1, 'objective': 'binary:logistic', 'learning_rate': 0.25, 'max_depth': 6, 'nthread': -1}
accuracy:  0.983
